-- Test coverage for previously uncovered lines
-- This test covers:
-- 0. Generic comparator for backward scans with upper bounds on non-INT/TEXT types (line 1048)
-- 1. Parallel claim batch > 1 (lines 2484-2529, 2647)
-- 2. Prefetch depth > 1 (lines 3417-3423)
-- 3. V2 RLE continues_byte skip (line 5274)
-- 4. key_len=1 for bool type (lines 3060, 3290)
-- 5. Defensive check for invalid key_len (lines 3066, 3296) - coverage mode only
-- Ensure we use V2 format for all RLE pages
SET smol.key_rle_version = 'v2';
-- =============================================================================
-- Test -1: Generic comparator for non-INT/TEXT backward scans (line 1048)
-- =============================================================================
-- Create UUID table with deterministic values
CREATE UNLOGGED TABLE t_uuid_back (k uuid);
INSERT INTO t_uuid_back VALUES
  ('00000000-0000-0000-0000-000000000001'::uuid),
  ('00000000-0000-0000-0000-000000000002'::uuid),
  ('00000000-0000-0000-0000-000000000003'::uuid),
  ('00000000-0000-0000-0000-000000000004'::uuid),
  ('00000000-0000-0000-0000-000000000005'::uuid),
  ('ffffffff-ffff-ffff-ffff-000000000001'::uuid),
  ('ffffffff-ffff-ffff-ffff-000000000002'::uuid);
CREATE INDEX t_uuid_back_smol ON t_uuid_back USING smol(k);
SET enable_seqscan = off;
-- Backward scan with upper bound on UUID triggers line 1048
SELECT k FROM t_uuid_back WHERE k <= 'ffffffff-ffff-ffff-ffff-000000000001'::uuid ORDER BY k DESC;
                  k                   
--------------------------------------
 ffffffff-ffff-ffff-ffff-000000000001
 00000000-0000-0000-0000-000000000005
 00000000-0000-0000-0000-000000000004
 00000000-0000-0000-0000-000000000003
 00000000-0000-0000-0000-000000000002
 00000000-0000-0000-0000-000000000001
(6 rows)

DROP TABLE t_uuid_back CASCADE;
-- TIMESTAMP with backward scan and upper bound
CREATE UNLOGGED TABLE t_ts_back (k timestamp);
INSERT INTO t_ts_back VALUES
  ('2024-01-01 00:00:00'),
  ('2024-06-01 00:00:00'),
  ('2024-12-01 00:00:00'),
  ('2024-12-15 00:00:00'),
  ('2024-12-31 23:59:59'),
  ('2025-01-01 00:00:00');
CREATE INDEX t_ts_back_smol ON t_ts_back USING smol(k);
-- Backward scan with upper bound on TIMESTAMP triggers line 1048
SELECT k FROM t_ts_back WHERE k <= '2024-12-31'::timestamp ORDER BY k DESC;
            k             
--------------------------
 Sun Dec 15 00:00:00 2024
 Sun Dec 01 00:00:00 2024
 Sat Jun 01 00:00:00 2024
 Mon Jan 01 00:00:00 2024
(4 rows)

DROP TABLE t_ts_back CASCADE;
-- FLOAT8 with backward scan and upper bound
CREATE UNLOGGED TABLE t_float_back (k float8);
INSERT INTO t_float_back VALUES (1.0), (2.5), (5.0), (10.5), (100.0), (999.0), (999.9), (1000.0);
CREATE INDEX t_float_back_smol ON t_float_back USING smol(k);
-- Backward scan with upper bound on FLOAT8 triggers line 1048
SELECT k FROM t_float_back WHERE k <= 999.9 ORDER BY k DESC;
   k   
-------
 999.9
   999
   100
  10.5
     5
   2.5
     1
(7 rows)

DROP TABLE t_float_back CASCADE;
-- =============================================================================
-- Test 0: 1-byte type (bool) coverage (lines 3060, 3290)
-- =============================================================================
-- Create bool table with many consecutive duplicates to trigger RLE
-- Add an extra column to force regular index scans (not index-only)
CREATE UNLOGGED TABLE t_bool (k bool, v int4);
-- Insert data that will create long RLE runs when sorted by index builder:
-- Generate values where first 50000 are false, next 50000 are true
INSERT INTO t_bool
  SELECT (i > 50000)::bool, i
  FROM generate_series(1, 100000) i;
VACUUM (FREEZE, ANALYZE) t_bool;
-- Create index on bool key only (not including v) to force regular index scans
CREATE INDEX t_bool_smol ON t_bool USING smol(k);
-- Scan to trigger smol_copy1() calls in both RLE paths (forward and backward)
SET enable_seqscan = off;
SET enable_bitmapscan = off;
-- Forward scans (will hit plain path line 3290)
SELECT count(*) FROM t_bool WHERE k = true;
 count 
-------
 50000
(1 row)

SELECT count(*) FROM t_bool WHERE k = false;
 count 
-------
 50000
(1 row)

-- **BACKWARD SCANS** to trigger RLE backward path (line 3060)
-- Use ORDER BY DESC with cursors to force backward scan
BEGIN;
DECLARE c CURSOR FOR SELECT k FROM t_bool WHERE k >= false ORDER BY k DESC;
FETCH 10 FROM c;
 k 
---
 t
 t
 t
 t
 t
 t
 t
 t
 t
 t
(10 rows)

CLOSE c;
COMMIT;
-- Another backward scan pattern
BEGIN;
DECLARE c2 CURSOR FOR SELECT k FROM t_bool WHERE k <= true ORDER BY k DESC;
FETCH 10 FROM c2;
 k 
---
 t
 t
 t
 t
 t
 t
 t
 t
 t
 t
(10 rows)

CLOSE c2;
COMMIT;
DROP TABLE t_bool CASCADE;
-- =============================================================================
-- Test 1: Parallel claim batch > 1 (covers lines 2484-2529, 2647)
-- =============================================================================
-- Create table WITHOUT INCLUDE to enable parallel build/scan
CREATE UNLOGGED TABLE t_parallel_batch (k int4);
INSERT INTO t_parallel_batch SELECT i FROM generate_series(1, 1000000) i ORDER BY 1;
ANALYZE t_parallel_batch;
-- Create SMOL index (no INCLUDE to allow parallel)
CREATE INDEX t_parallel_batch_smol ON t_parallel_batch USING smol(k);
-- Configure for parallel scan with claim batch > 1
SET smol.parallel_claim_batch = 3;  -- Claim 3 pages at once
SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;
SET parallel_tuple_cost = 0;
SET min_parallel_table_scan_size = 0;
SET min_parallel_index_scan_size = 0;
SET enable_seqscan = off;
SET enable_bitmapscan = off;
-- Force parallel index scan (planner will choose it with seqscan off)
EXPLAIN (COSTS OFF) SELECT count(*) FROM t_parallel_batch WHERE k > 100000;
                                         QUERY PLAN                                         
--------------------------------------------------------------------------------------------
 Finalize Aggregate
   ->  Gather
         Workers Planned: 4
         ->  Partial Aggregate
               ->  Parallel Index Only Scan using t_parallel_batch_smol on t_parallel_batch
                     Index Cond: (k > 100000)
(6 rows)

SELECT count(*) FROM t_parallel_batch WHERE k > 100000;
 count  
--------
 900000
(1 row)

-- Reset GUCs
SET smol.parallel_claim_batch = 1;
SET max_parallel_workers_per_gather = 2;
-- =============================================================================
-- Test 2: Prefetch depth > 1 with parallel scan (covers lines 3417-3423)
-- =============================================================================
-- Set prefetch depth BEFORE creating the table/index so workers see it
ALTER DATABASE contrib_regression SET smol.prefetch_depth = 4;
SELECT pg_reload_conf(); -- Ensure setting is active
 pg_reload_conf 
----------------
 t
(1 row)

CREATE UNLOGGED TABLE t_prefetch (k int4);
INSERT INTO t_prefetch SELECT i FROM generate_series(1, 200000) i ORDER BY 1;
VACUUM (FREEZE, ANALYZE) t_prefetch;
CREATE INDEX t_prefetch_smol ON t_prefetch USING smol(k);
SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;
SET parallel_tuple_cost = 0;
SET enable_seqscan = off;
SET enable_bitmapscan = off;
-- Run parallel scan to trigger aggressive prefetch logic
EXPLAIN (COSTS OFF) SELECT count(*) FROM t_prefetch WHERE k > 50000;
                                   QUERY PLAN                                   
--------------------------------------------------------------------------------
 Finalize Aggregate
   ->  Gather
         Workers Planned: 4
         ->  Partial Aggregate
               ->  Parallel Index Only Scan using t_prefetch_smol on t_prefetch
                     Index Cond: (k > 50000)
(6 rows)

SELECT count(*) FROM t_prefetch WHERE k > 50000;
 count  
--------
 150000
(1 row)

-- Reset database-level GUC
ALTER DATABASE contrib_regression RESET smol.prefetch_depth;
-- =============================================================================
-- Test 3: V2 RLE continues_byte skip (line 5274)
-- =============================================================================
-- This requires:
-- 1. Creating RLE pages with V2 format (text build path with v2 GUC)
-- 2. Scanning in a way that calls smol_leaf_run_bounds_rle_ex()
-- Create text table with duplicates (will use RLE compression)
CREATE UNLOGGED TABLE t_rle_v2_text (k text COLLATE "C", inc int4);
-- Insert sorted data with many duplicates to trigger RLE
INSERT INTO t_rle_v2_text
  SELECT 'key' || ((i % 10)::text), i
  FROM generate_series(1, 10000) i
  ORDER BY 1;
VACUUM (FREEZE, ANALYZE) t_rle_v2_text;
-- Force V2 format for text build path
SET smol.key_rle_version = 'v2';
-- Create index (will use text build path with V2 RLE)
CREATE INDEX t_rle_v2_text_smol ON t_rle_v2_text USING smol(k) INCLUDE (inc);
-- Scan with conditions that trigger run bounds checking
-- This should call smol_leaf_run_bounds_rle_ex() with V2 pages
SET enable_seqscan = off;
SET enable_bitmapscan = off;
-- Range scan that crosses RLE runs (triggers run bounds checking)
SELECT count(*), min(inc), max(inc)
FROM t_rle_v2_text
WHERE k >= 'key3' AND k <= 'key7';
 count | min | max  
-------+-----+------
  5000 |   3 | 9997
(1 row)

-- Scan with INCLUDE column access (triggers run bounds for INCLUDE data)
SELECT k, inc FROM t_rle_v2_text WHERE k = 'key5' LIMIT 10;
  k   | inc  
------+------
 key5 | 6995
 key5 | 9945
 key5 | 3605
 key5 | 4245
 key5 | 6005
 key5 | 4395
 key5 | 6985
 key5 | 2155
 key5 | 3215
 key5 | 6975
(10 rows)

-- Backward scan over RLE data (may trigger different code paths)
SELECT k FROM t_rle_v2_text WHERE k >= 'key5' ORDER BY k DESC LIMIT 5;
  k   
------
 key9
 key9
 key9
 key9
 key9
(5 rows)

-- =============================================================================
-- Test 4: Two-column parallel scan (covers line 2642)
-- =============================================================================
-- Set claim batch at database level for parallel workers
ALTER DATABASE contrib_regression SET smol.parallel_claim_batch = 3;
CREATE UNLOGGED TABLE t_twocol_parallel (k1 int4, k2 int4);
-- Insert MORE data to force parallel scan (5M rows instead of 500k)
INSERT INTO t_twocol_parallel
  SELECT i % 10000, i % 1000
  FROM generate_series(1, 5000000) i
  ORDER BY 1, 2;
ANALYZE t_twocol_parallel;
CREATE INDEX t_twocol_parallel_smol ON t_twocol_parallel USING smol(k1, k2);
ANALYZE t_twocol_parallel;
-- Force parallel scan for two-column index
SET max_parallel_workers_per_gather = 4;
SET parallel_setup_cost = 0;
SET parallel_tuple_cost = 0;
SET min_parallel_table_scan_size = 0;
SET min_parallel_index_scan_size = 0;
SET enable_seqscan = off;
SET enable_bitmapscan = off;
-- Two-column range scan (triggers two-col parallel path)
EXPLAIN (COSTS OFF) SELECT count(*) FROM t_twocol_parallel WHERE k1 > 100 AND k2 >= 0;
                                          QUERY PLAN                                          
----------------------------------------------------------------------------------------------
 Finalize Aggregate
   ->  Gather
         Workers Planned: 4
         ->  Partial Aggregate
               ->  Parallel Index Only Scan using t_twocol_parallel_smol on t_twocol_parallel
                     Index Cond: ((k1 > 100) AND (k2 >= 0))
(6 rows)

SELECT count(*) FROM t_twocol_parallel WHERE k1 > 100 AND k2 >= 0;
  count  
---------
 4949500
(1 row)

-- Reset database-level GUC
ALTER DATABASE contrib_regression RESET smol.parallel_claim_batch;
-- Reset GUCs
SET smol.parallel_claim_batch = 1;
SET smol.prefetch_depth = 1;
SET smol.key_rle_version = 'auto';
SET max_parallel_workers_per_gather = 2;
-- Cleanup
DROP TABLE t_parallel_batch CASCADE;
DROP TABLE t_prefetch CASCADE;
DROP TABLE t_rle_v2_text CASCADE;
DROP TABLE t_twocol_parallel CASCADE;
-- Success message
SELECT 'Coverage test completed successfully' AS result;
                result                
--------------------------------------
 Coverage test completed successfully
(1 row)

